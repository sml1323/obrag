"""
ChromaStore ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦½íŠ¸
"""

import sys
import tempfile
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent.parent
sys.path.insert(0, str(project_root / "src"))

from core.embedding import FakeEmbedder
from core.preprocessing import process_markdown_file, semantic_chunk
from core.sync import scan_and_process_folder
from db.chroma_store import (
    ChromaStore,
    create_store,
    search_chunks,
    store_chunks,
)


def main():
    # ì„ì‹œ ë””ë ‰í† ë¦¬ì— ChromaDB ì €ì¥ (í…ŒìŠ¤íŠ¸ìš©)
    with tempfile.TemporaryDirectory() as temp_dir:
        print(f"ğŸ“‚ ì„ì‹œ ì €ì¥ ê²½ë¡œ: {temp_dir}")
        print("=" * 60)
        print()

        # FakeEmbedder ì‚¬ìš© (API í˜¸ì¶œ ì—†ì´ í…ŒìŠ¤íŠ¸)
        embedder = FakeEmbedder(dimension=1536)

        # ========================================
        # 1. ChromaStore ìƒì„±
        # ========================================
        print("ğŸ”§ [1] ChromaStore ìƒì„±")
        print("-" * 40)

        store = ChromaStore(  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
            persist_path=temp_dir,
            collection_name="debug_collection",
            embedder=embedder,
        )

        stats = store.get_stats()
        print(f"  ì»¬ë ‰ì…˜ ì´ë¦„: {stats['name']}")
        print(f"  ì €ì¥ ê²½ë¡œ: {stats['persist_path']}")
        print(f"  ì„ë² ë”: {stats['embedder']}")
        print(f"  ì´ˆê¸° ì²­í¬ ìˆ˜: {stats['count']}")
        print()

        # ========================================
        # 2. í…ŒìŠ¤íŠ¸ ì²­í¬ ì¤€ë¹„
        # ========================================
        print("ğŸ“„ [2] í…ŒìŠ¤íŠ¸ ì²­í¬ ì¤€ë¹„")
        print("-" * 40)

        test_file = project_root / "src" / "test" / "Transformer models.md"
        if test_file.exists():
            chunks = process_markdown_file(test_file)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
            print(f"  íŒŒì¼: {test_file.name}")
            print(f"  ì²­í¬ ê°œìˆ˜: {len(chunks)}")
        else:
            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ì²­í¬ ìƒì„±
            from dataclasses import dataclass

            @dataclass
            class DummyChunk:
                text: str
                metadata: dict

            chunks = [
                DummyChunk(
                    text="TransformerëŠ” self-attention ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ëŠ” ë”¥ëŸ¬ë‹ ëª¨ë¸ì…ë‹ˆë‹¤.",
                    metadata={"source": "dummy.md", "header_path": "Transformer > ê°œìš”"},
                ),
                DummyChunk(
                    text="BERTëŠ” Bidirectional Encoder Representations from Transformersì…ë‹ˆë‹¤.",
                    metadata={"source": "dummy.md", "header_path": "BERT > ì†Œê°œ"},
                ),
                DummyChunk(
                    text="GPTëŠ” Generative Pre-trained Transformerì˜ ì•½ìì…ë‹ˆë‹¤.",
                    metadata={"source": "dummy.md", "header_path": "GPT > ê°œìš”"},
                ),
            ]
            print("  (í…ŒìŠ¤íŠ¸ íŒŒì¼ ì—†ìŒ, ë”ë¯¸ ì²­í¬ ì‚¬ìš©)")
            print(f"  ë”ë¯¸ ì²­í¬ ê°œìˆ˜: {len(chunks)}")

        print()

        # ========================================
        # 3. ì²­í¬ ì €ì¥ (upsert_chunks)
        # ========================================
        print("ğŸ’¾ [3] ì²­í¬ ì €ì¥ (upsert_chunks)")
        print("-" * 40)

        # upsert_chunksëŠ” ë©”íƒ€ë°ì´í„° ì •ê·œí™”ë¥¼ ìˆ˜í–‰í•¨
        source_name = chunks[0].metadata.get("source", "test.md") if chunks else "test.md"
        added_count = store.upsert_chunks(chunks, source_name)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!

        print(f"  ì €ì¥ëœ ì²­í¬ ìˆ˜: {added_count}")
        print(f"  í˜„ì¬ ì´ ì²­í¬ ìˆ˜: {store.get_stats()['count']}")
        print()

        # ========================================
        # 4. ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸ” [4] ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        query_text = "Transformer attention mechanism"
        results = store.query(query_text, n_results=3)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!

        print(f"  ì¿¼ë¦¬: \"{query_text}\"")
        print(f"  ê²°ê³¼ ìˆ˜: {len(results)}")
        print()

        for i, result in enumerate(results):
            print(f"  === ê²°ê³¼ {i + 1} ===")
            print(f"  ğŸ“ ID: {result['id']}")
            print(f"  ğŸ“ Distance: {result['distance']:.4f}")
            header_path = result['metadata'].get('header_path', 'N/A')
            print(f"  ğŸ·ï¸ Header Path: {header_path}")
            preview = result['text'][:80].replace("\n", " ")
            print(f"  ğŸ“ ë¯¸ë¦¬ë³´ê¸°: {preview}...")
            print()

        # ========================================
        # 5. Deterministic ID ìƒì„± í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸ”‘ [5] Deterministic ID ìƒì„± í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        test_path = "notes/test.md"
        for idx in range(3):
            chunk_id = ChromaStore.generate_deterministic_id(test_path, idx)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
            print(f"  [{idx}] {chunk_id}")
        print()

        # ========================================
        # 6. Upsert í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸ”„ [6] Upsert í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        # ìƒˆ store ìƒì„± (upsert í…ŒìŠ¤íŠ¸ìš©)
        upsert_store = ChromaStore(
            persist_path=temp_dir,
            collection_name="upsert_test",
            embedder=embedder,
        )

        relative_path = "notes/upsert_test.md"

        # ì²« ë²ˆì§¸ upsert
        from dataclasses import dataclass

        @dataclass
        class TestChunk:
            text: str
            metadata: dict

        initial_chunks = [
            TestChunk(text="Original content 1", metadata={"relative_path": relative_path}),
            TestChunk(text="Original content 2", metadata={"relative_path": relative_path}),
        ]

        count1 = upsert_store.upsert_chunks(initial_chunks, relative_path)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
        print(f"  ì²« ë²ˆì§¸ upsert: {count1}ê°œ ì²­í¬")
        print(f"  í˜„ì¬ ì´ ì²­í¬ ìˆ˜: {upsert_store.get_stats()['count']}")

        # ë‘ ë²ˆì§¸ upsert (ìˆ˜ì •ëœ ë‚´ìš©)
        updated_chunks = [
            TestChunk(text="UPDATED content 1", metadata={"relative_path": relative_path}),
            TestChunk(text="UPDATED content 2", metadata={"relative_path": relative_path}),
        ]

        count2 = upsert_store.upsert_chunks(updated_chunks, relative_path)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
        print(f"  ë‘ ë²ˆì§¸ upsert: {count2}ê°œ ì²­í¬")
        print(f"  í˜„ì¬ ì´ ì²­í¬ ìˆ˜: {upsert_store.get_stats()['count']} (ë³€í™” ì—†ì–´ì•¼ í•¨)")
        print()

        # ========================================
        # 7. ë©”íƒ€ë°ì´í„° ì •ê·œí™” í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸ“‹ [7] ë©”íƒ€ë°ì´í„° ì •ê·œí™” í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        test_metadata = {
            "source": "test.md",
            "tags": ["python", "ml"],  # ë¦¬ìŠ¤íŠ¸
            "frontmatter": {"author": "test"},  # ë”•ì…”ë„ˆë¦¬
            "count": 42,  # int
            "score": 0.95,  # float
            "active": True,  # bool
        }

        normalized = ChromaStore._normalize_metadata(test_metadata)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!

        print("  ì›ë³¸ ë©”íƒ€ë°ì´í„°:")
        for k, v in test_metadata.items():
            print(f"    {k}: {v} ({type(v).__name__})")

        print()
        print("  ì •ê·œí™”ëœ ë©”íƒ€ë°ì´í„°:")
        for k, v in normalized.items():
            print(f"    {k}: {v} ({type(v).__name__})")
        print()

        # ========================================
        # 8. ì²­í¬ ì‚­ì œ í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸ—‘ï¸ [8] ì²­í¬ ì‚­ì œ í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        before_count = upsert_store.get_stats()['count']
        print(f"  ì‚­ì œ ì „ ì²­í¬ ìˆ˜: {before_count}")

        upsert_store.delete_chunks_by_prefix(relative_path, from_index=1)  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!

        after_count = upsert_store.get_stats()['count']
        print(f"  ì‚­ì œ í›„ ì²­í¬ ìˆ˜: {after_count}")
        print()

        # ========================================
        # 9. clear í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸ§¹ [9] Clear í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        print(f"  Clear ì „ ì²­í¬ ìˆ˜: {store.get_stats()['count']}")
        store.clear()  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
        print(f"  Clear í›„ ì²­í¬ ìˆ˜: {store.get_stats()['count']}")
        print()

        # ========================================
        # 10. í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
        # ========================================
        print("ğŸš€ [10] í¸ì˜ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸")
        print("-" * 40)

        # create_store
        new_store = create_store(  # ğŸ‘ˆ ì—¬ê¸°ì— breakpoint!
            persist_path=temp_dir,
            collection_name="convenience_test",
            embedder=embedder,
        )
        print(f"  create_store: {new_store}")

        # store_chunks (add_chunks ì‚¬ìš©í•˜ë¯€ë¡œ upsertë¡œ ëŒ€ì²´)
        if chunks:
            new_store.upsert_chunks(chunks[:2], "convenience_test.md")
            print(f"  upsert_chunks: 2ê°œ ì €ì¥ë¨")

        # search_chunks
        search_results = search_chunks(
            "transformer",
            n_results=2,
            persist_path=temp_dir,
            collection_name="convenience_test",
            embedder=embedder,
        )
        print(f"  search_chunks: {len(search_results)}ê°œ ê²°ê³¼")
        print()

        print("âœ… ë””ë²„ê¹… ì™„ë£Œ!")


if __name__ == "__main__":
    main()
