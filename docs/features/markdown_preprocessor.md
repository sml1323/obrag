# MarkdownPreprocessor

ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ë¥¼ RAG ì‹œìŠ¤í…œìš©ìœ¼ë¡œ ì „ì²˜ë¦¬í•˜ëŠ” ëª¨ë“ˆì…ë‹ˆë‹¤.

---

## ğŸ”„ Processing Pipeline

![alt text](../images/image.png)
[code](../../src/core/preprocessing/markdown_preprocessor.py)

---

## ğŸ“¦ Data Classes

### YAMLFrontmatter

| Field         | Type            | Description      |
| ------------- | --------------- | ---------------- |
| `raw`         | `str`           | ì›ë³¸ YAML ë¬¸ìì—´ |
| `tags`        | `List[str]`     | íƒœê·¸ ëª©ë¡        |
| `create_date` | `Optional[str]` | ìƒì„±ì¼           |
| `extra`       | `dict`          | ê¸°íƒ€ ë©”íƒ€ë°ì´í„°  |

### HeaderMark

| Field          | Type        | Description                      |
| -------------- | ----------- | -------------------------------- |
| `position`     | `int`       | ë¬¸ì„œ ë‚´ ì‹œì‘ ìœ„ì¹˜                |
| `end_position` | `int`       | í—¤ë” ë¼ì¸ ë ìœ„ì¹˜                |
| `level`        | `int`       | í—¤ë” ë ˆë²¨ (1-6)                  |
| `title`        | `str`       | í—¤ë” ì œëª©                        |
| `path`         | `List[str]` | ìƒìœ„ í—¤ë” í¬í•¨ ê²½ë¡œ (breadcrumb) |

### Chunk

| Field      | Type   | Description                                  |
| ---------- | ------ | -------------------------------------------- |
| `text`     | `str`  | ì²­í¬ í…ìŠ¤íŠ¸                                  |
| `metadata` | `dict` | ë©”íƒ€ë°ì´í„° (source, headers, frontmatter ë“±) |

---

## ğŸ”§ Functions

### 1ï¸âƒ£ extract_frontmatter()

YAML frontmatterë¥¼ ì¶”ì¶œí•˜ê³  ë³¸ë¬¸ì—ì„œ ì œê±°í•©ë‹ˆë‹¤.

<details>
<summary><b>Input/Output ì˜ˆì‹œ</b></summary>

**Input:**

```markdown
---
tags:
  - AI
  - NLP
create: 2024-01-01
---

# Title

Content here...
```

**Output:** `Tuple[YAMLFrontmatter, str]`

```python
(
    YAMLFrontmatter(
        raw="tags:\n  - AI\n  - NLP\ncreate: 2024-01-01",
        tags=["AI", "NLP"],
        create_date="2024-01-01",
        extra={}
    ),
    "# Title\nContent here..."
)
```

</details>

---

### 2ï¸âƒ£ protect_code_blocks()

ì½”ë“œ ë¸”ë¡ì„ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ì¹˜í™˜í•˜ì—¬ ì²­í‚¹ ì‹œ ë¶„í• ë˜ì§€ ì•Šë„ë¡ ë³´í˜¸í•©ë‹ˆë‹¤.

<details>
<summary><b>Input/Output ì˜ˆì‹œ</b></summary>

**Input:**

````markdown
Some text

```python
def hello():
    print("world")
```
````

More text

````

**Output:** `Tuple[str, List[Tuple[str, str]]]`
```python
(
    "Some text\n\n__CODE_BLOCK_0__\n\nMore text",
    [
        ("__CODE_BLOCK_0__", "```python\ndef hello():\n    print(\"world\")\n```")
    ]
)
````

</details>

---

### 3ï¸âƒ£ extract_header_marks()

ë¬¸ì„œì—ì„œ ëª¨ë“  í—¤ë”ë¥¼ ì¶”ì¶œí•˜ê³  ê³„ì¸µ êµ¬ì¡°(breadcrumb)ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.

<details>
<summary><b>Input/Output ì˜ˆì‹œ</b></summary>

**Input:**

```markdown
# Transformer

## Architecture

### Encoder

### Decoder

## Training
```

**Output:** `List[HeaderMark]`

```python
[
    HeaderMark(position=0,  level=1, title="Transformer", path=["Transformer"]),
    HeaderMark(position=14, level=2, title="Architecture", path=["Transformer", "Architecture"]),
    HeaderMark(position=29, level=3, title="Encoder", path=["Transformer", "Architecture", "Encoder"]),
    HeaderMark(position=40, level=3, title="Decoder", path=["Transformer", "Architecture", "Decoder"]),
    HeaderMark(position=51, level=2, title="Training", path=["Transformer", "Training"]),
]
```

</details>

---

### 4ï¸âƒ£ semantic_chunk() â­ í•µì‹¬ í•¨ìˆ˜

ë§ˆí¬ë‹¤ìš´ì„ í—¤ë” ê¸°ë°˜ìœ¼ë¡œ Semantic Chunkingí•©ë‹ˆë‹¤.

```mermaid
flowchart TD
    A[semantic_chunk] --> B{í—¤ë” ë ˆë²¨ ì²´í¬}
    B --> |"level <= chunk_level"| C[ìƒˆ ì²­í¬ ì‹œì‘]
    B --> |"level > chunk_level"| D[í˜„ì¬ ì²­í¬ì— ë³‘í•©]

    C --> E{ì²­í¬ í¬ê¸° ì²´í¬}
    D --> E

    E --> |"< min_size"| F[ì´ì „ ì²­í¬ì™€ ë³‘í•©]
    E --> |"> max_size"| G[ë¬¸ë‹¨ ë‹¨ìœ„ ë¶„í• ]
    E --> |"ì ì • í¬ê¸°"| H[ê·¸ëŒ€ë¡œ ì €ì¥]

    F --> I["List[Chunk]"]
    G --> I
    H --> I
```

| Parameter        | Type   | Default    | Description                         |
| ---------------- | ------ | ---------- | ----------------------------------- |
| `text`           | `str`  | _required_ | ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸                     |
| `source`         | `str`  | _required_ | ì›ë³¸ íŒŒì¼ëª…                         |
| `extra_metadata` | `dict` | `None`     | ì¶”ê°€ ë©”íƒ€ë°ì´í„°                     |
| `min_size`       | `int`  | `200`      | ìµœì†Œ ì²­í¬ í¬ê¸° (ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ë³‘í•©) |
| `max_size`       | `int`  | `1500`     | ìµœëŒ€ ì²­í¬ í¬ê¸° (ì´ë³´ë‹¤ ê¸¸ë©´ ë¶„í• )   |
| `chunk_level`    | `int`  | `2`        | ì²­í‚¹ ê¸°ì¤€ í—¤ë” ë ˆë²¨ (## = 2)        |

<details>
<summary><b>Input/Output ì˜ˆì‹œ</b></summary>

**Input:**

```python
text = """
---
tags:
  - AI
---
# Transformer

## Architecture
The transformer architecture...

### Encoder
Encoder details...

## Training
Training process...
"""

chunks = semantic_chunk(
    text=text,
    source="transformer.md",
    min_size=200,
    max_size=1500,
    chunk_level=2
)
```

**Output:** `List[Chunk]`

```python
[
    Chunk(
        text="## Architecture\nThe transformer architecture...\n\n### Encoder\nEncoder details...",
        metadata={
            "source": "transformer.md",
            "header_path": "# Transformer > ## Architecture",
            "headers": ["Architecture", "Encoder"],
            "level": 2,
            "frontmatter": {"tags": ["AI"], "create_date": None}
        }
    ),
    Chunk(
        text="## Training\nTraining process...",
        metadata={
            "source": "transformer.md",
            "header_path": "# Transformer > ## Training",
            "headers": ["Training"],
            "level": 2,
            "frontmatter": {"tags": ["AI"], "create_date": None}
        }
    )
]
```

</details>

---

### 5ï¸âƒ£ process_markdown_file()

íŒŒì¼ ê²½ë¡œë¥¼ ë°›ì•„ ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” í¸ì˜ í•¨ìˆ˜ì…ë‹ˆë‹¤.

```python
from src.core.preprocessing import process_markdown_file

chunks = process_markdown_file("/path/to/document.md")
```

---

## ğŸš€ Quick Start

```python
from src.core.preprocessing import semantic_chunk, process_markdown_file

# ë°©ë²• 1: í…ìŠ¤íŠ¸ ì§ì ‘ ì²˜ë¦¬
text = open("document.md").read()
chunks = semantic_chunk(
    text=text,
    source="document.md",
    chunk_level=2  # ## ë‹¨ìœ„ë¡œ ì²­í‚¹
)

# ë°©ë²• 2: íŒŒì¼ ê²½ë¡œë¡œ ì²˜ë¦¬
chunks = process_markdown_file("document.md")

# ê²°ê³¼ í™•ì¸
for chunk in chunks:
    print(f"Headers: {chunk.metadata['headers']}")
    print(f"Text: {chunk.text[:100]}...")
```

---

## ğŸ”— Related Modules

- **[FolderScanner](../../src/core/sync/folder_scanner.py)** - í´ë” ìŠ¤ìº” í›„ ì´ ëª¨ë“ˆë¡œ ì²­í‚¹
- **[debug_preprocessor.py](../../src/tasktests/phase1/debug_preprocessor.py)** - ë””ë²„ê¹…ìš© ìŠ¤í¬ë¦½íŠ¸
